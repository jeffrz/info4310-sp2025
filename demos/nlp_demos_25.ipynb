{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6063808a-c985-41da-b32e-c2d6a14bff4f",
   "metadata": {},
   "source": [
    "# NLP Demos\n",
    "## Setup\n",
    "Make sure that you install the `transformers` and `bertviz` libraries. You may also need to install a backend ML support library like PyTorch, Keras, or TensorFlow.\n",
    "\n",
    "This demo is heavily based on the walkthroughs and demos provided by the author of bertviz at its [repository](https://github.com/jessevig/bertviz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664a493-7c2b-4391-bef0-be3efeec9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498522b-8803-47ae-89b6-64d35996908c",
   "metadata": {},
   "source": [
    "## Importing BERT\n",
    "Most models that you will use for basic tasks will come pretrained from repositories such as HuggingFace. The `transformers` package does a great job automatically downloading and setting up models for you. Notice that we set `output_attentions` to true so that we can store extra data about model runs for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25f2e6-8287-4326-9c81-bde86369af15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b039c8-5b52-405d-b74e-00f9848de62a",
   "metadata": {},
   "source": [
    "## Running the model on a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c699ed-07bd-4544-a078-2777354675dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The tired fox wrapped itself in a blanket to keep warm.\"\n",
    "\n",
    "inputs = tokenizer.encode(sentence, return_tensors='pt') # encode sentence using tokenizer\n",
    "outputs = model(inputs) # run model on tokens\n",
    "attention = outputs[-1] # take the attentions from the output\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # store representation of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac9146-b7d3-4676-b78b-b66d1cba17a5",
   "metadata": {},
   "source": [
    "## Basic visualization of attention\n",
    "\n",
    "See [part 1](https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77) and [part 2](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1) by the author of BertViz to get a sense for what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7043a8-77f0-4aa1-85e9-30ed8eb64e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import model_view\n",
    "\n",
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04623240-b298-4997-8f9f-3db4824eb081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8d0b0-2897-4c49-8f7b-376a5165e1c8",
   "metadata": {},
   "source": [
    "## Neuron view of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc3a56-78af-43c0-b99e-085e0a39df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
    "from bertviz.neuron_view import show\n",
    "\n",
    "model_type = 'bert'\n",
    "model_version = 'bert-base-uncased'\n",
    "do_lower_case = True\n",
    "sentence_a = \"The fox sat on a blanket to keep warm.\"\n",
    "sentence_b = \"The fox lay on a blanket to stay warm\"\n",
    "model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)\n",
    "show(model, model_type, tokenizer, sentence_a, sentence_b, display_mode='light', layer=2, head=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afec4cc-1269-4e7f-b926-2634efe4bd18",
   "metadata": {},
   "source": [
    "## Comparing with GPT-2\n",
    "Recall the architectural differences we discussed between BERT and GPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842514ea-a3a7-41c5-9f73-c38deae8b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz.transformers_neuron_view import GPT2Model, GPT2Tokenizer\n",
    "from bertviz.neuron_view import show\n",
    "\n",
    "model_type = 'gpt2'\n",
    "model_version = 'gpt2'\n",
    "model = GPT2Model.from_pretrained(model_version)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "text = \"At the store, she bought apples, oranges, and pineapple,\"\n",
    "show(model, model_type, tokenizer, text, display_mode='light')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb6c83-0ca4-4c38-bd28-97467e5327f5",
   "metadata": {},
   "source": [
    "## Examining an encoder-decoder setup\n",
    "Encoder-decoder models work as you might guess from the name. First, the model encodes some text into a vector representation. Then, the decoder takes that representation and turns it back into text again (usually in a different form). Here we'll use the MarianMT model series for english to french translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab9255-1e37-42c1-957d-ca3d78ce779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "model = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\", output_attentions=True)\n",
    "\n",
    "# Encode and decode some text\n",
    "encoder_input_ids = tokenizer(\"My dog doesn't have a nose.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    decoder_input_ids = tokenizer(\"Mon chien n'a pas de nez.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "from bertviz import model_view\n",
    "model_view(\n",
    "    encoder_attention=outputs.encoder_attentions,\n",
    "    decoder_attention=outputs.decoder_attentions,\n",
    "    cross_attention=outputs.cross_attentions,\n",
    "    encoder_tokens= encoder_text,\n",
    "    decoder_tokens = decoder_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc89bb-4bcb-4f8b-95aa-4a8c42fa6b80",
   "metadata": {},
   "source": [
    "Now one more, this time for BART fine-tuned for summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0810263-b1ef-4268-bf5e-a2c3e6b8f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "from bertviz import model_view\n",
    "\n",
    "# Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_attentions=True)\n",
    "\n",
    "# get encoded input vectors\n",
    "encoder_input_ids = tokenizer(\"Mayor Eric Adams is amassing a team of high-powered lawyers paid by city taxpayer and donor money.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "# create ids of encoded input vectors\n",
    "decoder_input_ids = tokenizer(\"Mayor Adams builds team of lawyers using taxpayer money.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n",
    "\n",
    "model_view(\n",
    "    encoder_attention=outputs.encoder_attentions,\n",
    "    decoder_attention=outputs.decoder_attentions,\n",
    "    cross_attention=outputs.cross_attentions,\n",
    "    encoder_tokens= encoder_text,\n",
    "    decoder_tokens=decoder_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5128f21-3528-4a2e-94db-f96d18aa0398",
   "metadata": {},
   "source": [
    "## More things to try\n",
    "\n",
    "- The [Ecco](https://github.com/jalammar/ecco/) library is also very interesting, but can be very finicky to set up (especially on arm64 Macs). You can see some of their examples [here](https://ecco.readthedocs.io/en/main/)\n",
    "- For something even more fully featured, check out [LIT](https://github.com/PAIR-code/lit)\n",
    "- HuggingFace also hosts the [Exbert](https://huggingface.co/spaces/exbert-project/exbert) tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d08607-7bde-439a-a82b-c1be8ea4735c",
   "metadata": {},
   "source": [
    "### LIT demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d70cb9-a0c3-42e5-bc35-9be88a4ccff4",
   "metadata": {},
   "source": [
    "After installing, try:\n",
    "- `python -m lit_nlp.examples.glue_demo --quickstart --port=5431`\n",
    "- `python -m lit_nlp.examples.image_demo --port=5431`\n",
    "- `python -m lit_nlp.examples.toxicity_demo --port=5431`\n",
    "\n",
    "Navigate to [localhost:5431](http://localhost:5431)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
